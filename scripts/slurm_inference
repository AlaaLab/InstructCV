#!/bin/bash
#SBATCH -o %j.out
#SBATCH --gres=gpu:1
#SBATCH -p gpu32
#SBATCH --qos=normal
#SBATCH -J test
#SBATCH --nodes=1 
#SBATCH -t 48:00:00

#source activate esmfold
# python edit_cli.py --input imgs/woody.jpeg --output imgs/woody_seg4.jpeg --edit "segment the person"
# python edit_cli.py --input imgs/woody.jpeg --output imgs/woody_seg2.jpeg --edit "segment the image"
# python edit_cli.py --input imgs/woody.jpeg --output imgs/woody_seg3.jpeg --edit "segment all"
# python edit_cli.py --input imgs/woody.jpeg --output imgs/woody_det13.jpeg --edit "detect the woody"
# python edit_cli.py --input imgs/woody.jpeg --output imgs/woody_det14.jpeg --edit "detect the person"
# python edit_cli.py --input imgs/woody.jpeg --output imgs/woody_det15.jpeg --edit "detect the man"
# python edit_cli.py --input imgs/woody.jpeg --output imgs/woody_detect2.jpeg --edit "detect the face"

## for det:
# python edit_cli.py --input imgs_test_coco/ --output imgs/ --edit "detect the person"

## for seg:
# python edit_cli.py --input data/ade20k/images/ADE/training/cultural/apse__indoor/ADE_train_00001472.jpg --output imgs/ADE_train_00001472_seg.jpeg --edit "segment the person"

## for cls:
CUDA_VISIBLE_DEVICES=1 python edit_cli.py --ckpt logs/train_pets_cls_pets/checkpoints/last.ckpt --resolution 128 --input data/oxford-pets --output outputs/img_test_cls_rp --edit "Show * if there exsits %; if not, show # instead." --task cls --split test.txt
## for debug
CUDA_VISIBLE_DEVICES=6 python edit_cli.py --split "test_part4.txt" --ckpt logs/train_all100kdata_rephrased_newnew/checkpoints/last.ckpt --resolution 256 --input data/ADEChallengeData2016/ --output outputs/img_test_ade20k_rephrasedv2 --edit "Perform image segmentation to extract the % using different colors." --task seg

## for depth estimation
# python edit_cli_depes.py --input /lustre/grp/gyqlab/lism/brt/language-vision-interface/data/nyuv2/basement_0001a --output imgs_test_nyuv2/ --edit "Assess the image's depth by looking for visual cues and making an estimation."


## for pets
# python edit_cli_cls.py --resolution 256 --ckpt logs/train_all100kdata_new/checkpoints/epoch=000051.ckpt --input data/oxford-pets/images --output outputs/imgs_test_oxford_pets/ --edit "show blue if the picture contain %" --task cls
# python edit_cli_seg.py --input data/oxford-pets/images --output imgs_test_oxford_pets/ --edit "segment the %" --task seg
# python edit_cli_det.py --ckpt logs/train_pets_nyuv2_four_tasks_depsprompt:image/checkpoints/last.ckpt --input data/oxford-pets/images --output data/image_pairs_evaluation_det --edit "detect the %" --task det

## for nyuv2
# CUDA_VISIBLE_DEVICES=2 python edit_cli.py --resolution 256 --ckpt --ckpt logs/train_nyuv2_depes/checkpoints/epoch=000049.ckpt --input data/nyu_mdet/ --output "outputs/imgs_test_nyuv2_test_0606" --edit "Estimate the depth of this image"  --task depes

## for ade20k
# CUDA_VISIBLE_DEVICES=6 python edit_cli.py --resolution 256 --split "test_part8.txt" --ckpt logs/train_rp_model_archived_version/checkpoints/51_bold5_loss0.0234.ckpt --input data/ADEChallengeData2016/ --output outputs/imgs_test_ade20k --edit "Segment %." --task seg

## for voc seg
# CUDA_VISIBLE_DEVICES=2 python edit_cli.py --resolution 256 --split "val_part5.txt" --ckpt logs/train_all100kdata_add_coco_pet_seg/checkpoints/epoch=000038.ckpt --input /lustre/grp/gyqlab/lism/brt/language-vision-interface/data/VOCdevkit/VOC2012 --output outputs/imgs_test_voc  --edit "segment the %" --task voc_seg

## for voc det
# python edit_cli.py --resolution 256 --split "val_part0.txt" --ckpt logs/train_rp_model_archived_version/checkpoints/47.ckpt --input /lustre/grp/gyqlab/lism/brt/language-vision-interface/data/VOCdevkit/VOC2012 --output outputs/imgs_test_voc_det_rp  --edit "Detect the %." --task voc_det --eval

# for coco det
CUDA_VISIBLE_DEVICES=3 python edit_cli.py --resolution 512 --split "test_part4.txt" --ckpt logs/train_rp_model_archived_version/checkpoints/51_bold5_loss0.0234.ckpt --input data/coco --output ./outputs/imgs_test_coco_rp/ --edit "Detect the %." --task det

# for coco seg
CUDA_VISIBLE_DEVICES=0 python edit_cli.py --resolution 256 --ckpt logs/train_rp_model_archived_version/checkpoints/51_bold5_loss0.0234.ckpt --input data/coco --output ./outputs/imgs_test_coco_seg/ --edit "Segment the %." --task seg_coco

# for unified-io 
# CUDA_VISIBLE_DEVICES=0 python baselines/unified-io-inference/demo_script.py

# for fs-1000
# python edit_cli.py --resolution 256 --ckpt logs/train_rp_model_archived_version/checkpoints/47.ckpt --input data/fewshot_data/fewshot_data --output outputs/imgs_test_fs1000/ --edit "segment the %" --task fs1000_seg
## unified-io
# python baselines/unified-io-inference/demo_script_seg_fs1000.py

# for sunrgbd
# CUDA_VISIBLE_DEVICES=4 python edit_cli.py --test_txt_path data/SUNRGBD/SUNRGBD_val_splits4.txt --resolution 256 --ckpt logs/train_all100kdata_new/checkpoints/epoch=000051.ckpt --input data/ --output outputs/imgs_test_sunrgbd/ --edit "Estimate the depth of this image" --task sunrgbd_depes
## unified-io

# for pet seg
CUDA_VISIBLE_DEVICES=7 python edit_cli.py --resolution 256 --ckpt logs/train_all100kdata_add_coco_pet_seg_blue/checkpoints/epoch=000020.ckpt --input data/oxford-pets --output ./outputs/imgs_test_pets_seg/ --edit "segment the %" --task pet_seg

# for fig1
python edit_cli.py --ckpt logs/train_rp_model_hug/checkpoints/28.ckpt --resolution 512 --input visualization/ori_img --output outputs/img_test_cls --edit "Detect Woody using a blue bounding box." --task det --single_test

## for vis_depes
# python edit_cli.py --ckpt logs/train_fp_model_archived_version/checkpoints/epoch=000042.ckpt --input outputs/test_img --output outputs/visualization_depes --edit "Estimate the depth of this image" --task depes --single_test

CUDA_VISIBLE_DEVICES=2 python edit_cli.py --resolution 256 --split "test_part0.txt" --ckpt logs/train_fp_model_archived_version/checkpoints/epoch=000042.ckpt  --input data/ADEChallengeData2016 --output outputs/imgs_test_ade20k_please_segment/ --edit "Please segment the % into smaller parts" --task seg